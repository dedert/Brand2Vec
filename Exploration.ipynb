{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import csv\n",
    "import nltk, re\n",
    "import datetime\n",
    "import random\n",
    "import multiprocessing\n",
    "from ast import literal_eval\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = \"E:/dataset/Amazon/\"\n",
    "result_path = \"E:/dataset/MasterThesis/FINAL/\"\n",
    "save_path = \"E:/dataset/MasterThesis/FINAL/preprocess_data/\"\n",
    "model_path = \"E:/dataset/MasterThesis/FINAL/doc2vec/\"\n",
    "category_list = [\"Electronics\"]\n",
    "for category in category_list:\n",
    "    data = pd.read_csv(save_path + \"preprocess_complete_\" + category + \".csv\")\n",
    "    data['preprocessed'] = data.preprocessed.apply(lambda row: literal_eval(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>overall</th>\n",
       "      <th>helpful</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>title</th>\n",
       "      <th>brand</th>\n",
       "      <th>reviewSentence</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>reviewSentence_tagged</th>\n",
       "      <th>preprocessed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-07-21</td>\n",
       "      <td>B00CM0XHNS</td>\n",
       "      <td>A372YX80GGM7DR</td>\n",
       "      <td>5.0</td>\n",
       "      <td>576</td>\n",
       "      <td>Ok, so I didn't buy this on Amazon, as I didn'...</td>\n",
       "      <td>Ultimate Ears BOOM Wireless Bluetooth Speaker ...</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>[\"Ok, so I didn't buy this on Amazon, as I did...</td>\n",
       "      <td>58</td>\n",
       "      <td>[[('Ok', 'NNP'), (',', ','), ('so', 'IN'), ('I...</td>\n",
       "      <td>[[ok, so, i, did, n't, buy, this, on, amazon, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-05-19</td>\n",
       "      <td>B00BQ5RY1G</td>\n",
       "      <td>A1BG2Z071TYO7P</td>\n",
       "      <td>2.0</td>\n",
       "      <td>522</td>\n",
       "      <td>I received a Harmony Ultimate from Logitech be...</td>\n",
       "      <td>Logitech Harmony Ultimate Remote with Customiz...</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>['I received a Harmony Ultimate from Logitech ...</td>\n",
       "      <td>27</td>\n",
       "      <td>[[('I', 'PRP'), ('received', 'VBD'), ('a', 'DT...</td>\n",
       "      <td>[[i, received, a, harmony, ultimate, from, log...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-12-16</td>\n",
       "      <td>B00EZ9XG62</td>\n",
       "      <td>AELAESM03451</td>\n",
       "      <td>1.0</td>\n",
       "      <td>290</td>\n",
       "      <td>This review is for the iPad Air keyboard. I ha...</td>\n",
       "      <td>Logitech Ultrathin Keyboard Cover for iPad Air...</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>['This review is for the iPad Air keyboard.', ...</td>\n",
       "      <td>23</td>\n",
       "      <td>[[('This', 'DT'), ('review', 'NN'), ('is', 'VB...</td>\n",
       "      <td>[[this, review, is, for, the, ipad, air, keybo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-21</td>\n",
       "      <td>B0099SMFVQ</td>\n",
       "      <td>A36CMGR5ELUM34</td>\n",
       "      <td>5.0</td>\n",
       "      <td>283</td>\n",
       "      <td>Design: Very well put together. Elegant and th...</td>\n",
       "      <td>Logitech Bluetooth Illuminated Keyboard K810 f...</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>['Design: Very well put together.', 'Elegant a...</td>\n",
       "      <td>28</td>\n",
       "      <td>[[('Design', 'NN'), (':', ':'), ('Very', 'RB')...</td>\n",
       "      <td>[[design, very, well, put, together], [elegant...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-07-29</td>\n",
       "      <td>B00CM0XHNS</td>\n",
       "      <td>A9TETE58A7JR3</td>\n",
       "      <td>3.0</td>\n",
       "      <td>260</td>\n",
       "      <td>So, I've been testing a few bluetooth speakers...</td>\n",
       "      <td>Ultimate Ears BOOM Wireless Bluetooth Speaker ...</td>\n",
       "      <td>Logitech</td>\n",
       "      <td>[\"So, I've been testing a few bluetooth speake...</td>\n",
       "      <td>57</td>\n",
       "      <td>[[('So', 'RB'), (',', ','), ('I', 'PRP'), (\"'v...</td>\n",
       "      <td>[[so, i, been, testing, a, few, bluetooth, spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reviewTime        asin      reviewerID  overall  helpful  \\\n",
       "0  2013-07-21  B00CM0XHNS  A372YX80GGM7DR      5.0      576   \n",
       "1  2013-05-19  B00BQ5RY1G  A1BG2Z071TYO7P      2.0      522   \n",
       "2  2013-12-16  B00EZ9XG62    AELAESM03451      1.0      290   \n",
       "3  2013-01-21  B0099SMFVQ  A36CMGR5ELUM34      5.0      283   \n",
       "4  2013-07-29  B00CM0XHNS   A9TETE58A7JR3      3.0      260   \n",
       "\n",
       "                                          reviewText  \\\n",
       "0  Ok, so I didn't buy this on Amazon, as I didn'...   \n",
       "1  I received a Harmony Ultimate from Logitech be...   \n",
       "2  This review is for the iPad Air keyboard. I ha...   \n",
       "3  Design: Very well put together. Elegant and th...   \n",
       "4  So, I've been testing a few bluetooth speakers...   \n",
       "\n",
       "                                               title     brand  \\\n",
       "0  Ultimate Ears BOOM Wireless Bluetooth Speaker ...  Logitech   \n",
       "1  Logitech Harmony Ultimate Remote with Customiz...  Logitech   \n",
       "2  Logitech Ultrathin Keyboard Cover for iPad Air...  Logitech   \n",
       "3  Logitech Bluetooth Illuminated Keyboard K810 f...  Logitech   \n",
       "4  Ultimate Ears BOOM Wireless Bluetooth Speaker ...  Logitech   \n",
       "\n",
       "                                      reviewSentence  sent_length  \\\n",
       "0  [\"Ok, so I didn't buy this on Amazon, as I did...           58   \n",
       "1  ['I received a Harmony Ultimate from Logitech ...           27   \n",
       "2  ['This review is for the iPad Air keyboard.', ...           23   \n",
       "3  ['Design: Very well put together.', 'Elegant a...           28   \n",
       "4  [\"So, I've been testing a few bluetooth speake...           57   \n",
       "\n",
       "                               reviewSentence_tagged  \\\n",
       "0  [[('Ok', 'NNP'), (',', ','), ('so', 'IN'), ('I...   \n",
       "1  [[('I', 'PRP'), ('received', 'VBD'), ('a', 'DT...   \n",
       "2  [[('This', 'DT'), ('review', 'NN'), ('is', 'VB...   \n",
       "3  [[('Design', 'NN'), (':', ':'), ('Very', 'RB')...   \n",
       "4  [[('So', 'RB'), (',', ','), ('I', 'PRP'), (\"'v...   \n",
       "\n",
       "                                        preprocessed  \n",
       "0  [[ok, so, i, did, n't, buy, this, on, amazon, ...  \n",
       "1  [[i, received, a, harmony, ultimate, from, log...  \n",
       "2  [[this, review, is, for, the, ipad, air, keybo...  \n",
       "3  [[design, very, well, put, together], [elegant...  \n",
       "4  [[so, i, been, testing, a, few, bluetooth, spe...  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# documents for doc2vec\n",
    "with open(result_path  + category + '_documents.pkl', 'rb') as f:\n",
    "    documents = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def brands_text(documents, data, brand):\n",
    "    df = data[data['brand']==brand]\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df = df[['asin', 'reviewerID', 'overall', 'helpful', 'reviewText', 'title', 'brand']]\n",
    "    reviews = []\n",
    "    for doc in documents:\n",
    "        if doc.tags[0] == brand:\n",
    "            reviews.append(doc.words)\n",
    "    corpus = [word for sent in reviews for word in sent]\n",
    "    corpus = nltk.Text(corpus)\n",
    "    return df, reviews, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_word(nltk_finder_result, target_word):\n",
    "    find_word = target_word\n",
    "    n_gram_list = []\n",
    "    for i in nltk_finder_result:\n",
    "        if len(n_gram_list) > 10:\n",
    "            break\n",
    "        elif i[0][0] == find_word or i[0][1] == find_word:\n",
    "            n_gram_list.append(i)\n",
    "    return n_gram_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#단어에 대해서 bigram(pmi) 확인\n",
    "import nltk\n",
    "from nltk.collocations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "samsung_df, samsung_lst, samsung_txt = brands_text(documents, data, 'Samsung')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 4\n",
    "min_count = 10\n",
    "\n",
    "samsung_bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "s_finder = BigramCollocationFinder.from_words(samsung_txt, window_size = window)\n",
    "\n",
    "s_finder.apply_freq_filter(min_count) #13번 미만으로 나온 것들 무시\n",
    "#finder.nbest(bigram_measures.pmi, 20)\n",
    "s_result = s_finder.score_ngrams(samsung_bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "picture_quality\n",
      "\n",
      "\n",
      "[(('picture_quality', 'amazing'), 4.781451833888468), (('great', 'picture_quality'), 3.2950439151871223), (('picture_quality', 'good'), 2.936099648589078), (('picture_quality', 'sound'), 2.7408098493911197), (('picture_quality', 'great'), 2.710081414465968), (('better', 'picture_quality'), 2.671461802700385), (('picture_quality', 'is'), 2.4319344330527315), (('good', 'picture_quality'), 2.043014852505589), (('tv', 'picture_quality'), 1.7883875263668827), (('the', 'picture_quality'), 1.753679335107524), (('picture_quality', 'was'), 1.6898069459570202)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "basic\n",
      "\n",
      "\n",
      "[(('some', 'basic'), 3.2492125612020075), (('very', 'basic'), 2.6305726013640793), (('for', 'basic'), 1.7960063002534419), (('a', 'basic'), 1.3938724462796976), (('with', 'basic'), 1.215878138302628), (('basic', 'for'), 0.9765785458952649), (('basic', 'and'), 0.9601669243632003), (('is', 'basic'), 0.5079986316275757), (('the', 'basic'), 0.4726165305761043), (('basic', 'that'), 0.38073339344517265), (('basic', 'of'), 0.3510292852891794)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "lag\n",
      "\n",
      "\n",
      "[(('no', 'lag'), 4.515752402182041), (('little', 'lag'), 4.113788040907643), (('any', 'lag'), 3.842606761864804), (('there', 'lag'), 3.7029958075143448), (('lag', 'time'), 3.1476508589010272), (('some', 'lag'), 2.6932937195649416), (('lag', 'when'), 2.609703887461805), (('lag', 'or'), 2.1711413710600382), (('is', 'lag'), 1.6192570539998528), (('lag', 'but'), 1.2225442761337284), (('with', 'lag'), 1.1302792314455878)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "compared\n",
      "\n",
      "\n",
      "[(('compared', 'lines'), 7.347740130447223), (('compared', 'ipad'), 4.284507505669318), (('features', 'compared'), 3.873915911421662), (('compared', 'other'), 3.7211703089324892), (('best', 'compared'), 3.649667933506734), (('compared', 'to'), 3.3788548128824054), (('when', 'compared'), 3.1467839825057418), (('compared', 'what'), 2.204126406120757), (('compared', 'my'), 2.107214077394744), (('as', 'compared'), 1.7814651355821027), (('very', 'compared'), 1.7537528596433773)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pmi\n",
    "target_word = ['picture_quality', 'basic', 'lag','compared']\n",
    "for i in target_word:\n",
    "    print( \"-------------\")\n",
    "    print(i)\n",
    "    print('\\n')\n",
    "    print(find_word(s_result, i))\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for target in target_word:\n",
    "    target_index = []\n",
    "    for index, review in enumerate(samsung_lst):\n",
    "        if target in review:\n",
    "            target_index.append(index)\n",
    "    samsung_df.loc[target_index].to_csv(interprete_path + 'samsung_' + target + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Microsoft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ms_df, ms_lst, ms_txt = brands_text(documents, data, 'Microsoft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 4\n",
    "min_count = 10\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "s_finder = BigramCollocationFinder.from_words(ms_txt, window_size = window)\n",
    "\n",
    "s_finder.apply_freq_filter(min_count) #13번 미만으로 나온 것들 무시\n",
    "#finder.nbest(bigram_measures.pmi, 20)\n",
    "s_result = s_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "ergonomic\n",
      "\n",
      "\n",
      "[(('microsoft_sculpt', 'ergonomic'), 8.070524720096817), (('an', 'ergonomic'), 2.767492607212777), (('ergonomic', 'mouse'), 2.7551627994931422), (('very', 'ergonomic'), 2.2368880337645116), (('is', 'ergonomic'), 0.7642172428184502), (('ergonomic', 'is'), 0.6862147308171735), (('the', 'ergonomic'), 0.6082068378240315), (('ergonomic', 'and'), 0.5106219634075728), (('ergonomic', 'this'), 0.43942520988136025), (('for', 'ergonomic'), 0.4064592786489172), (('ergonomic', 'i'), 0.06289539289234725)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "natural\n",
      "\n",
      "\n",
      "[(('natural', 'position'), 6.837483132987684), (('feels', 'natural'), 5.546348191645926), (('natural', 'keyboards'), 4.6556595482988), (('feel', 'natural'), 4.2553746293216825), (('more', 'natural'), 4.198393322514562), (('natural', 'keyboard'), 3.0426435054241097), (('in', 'natural'), 1.9026384758081676), (('a', 'natural'), 1.142568342770275), (('natural', 'for'), 1.1326811009870674), (('the', 'natural'), 1.1114211481999625), (('natural', 'in'), 1.0401419995581023)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "easily\n",
      "\n",
      "\n",
      "[(('quickly', 'easily'), 4.930303507018408), (('can', 'easily'), 4.032293939220757), (('easily', 'into'), 3.9010162800501647), (('could', 'easily'), 3.4812634942277114), (('easily', 'by'), 3.3369123842266717), (('small', 'easily'), 2.9231487879364657), (('very', 'easily'), 2.331037468267759), (('so', 'easily'), 1.7243745320422548), (('easily', 'in'), 1.7219922439081756), (('be', 'easily'), 1.4878207153220515), (('easily', 'be'), 1.3882850417711374)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pmi\n",
    "target_word = ['ergonomic', 'natural','easily']\n",
    "for i in target_word:\n",
    "    print( \"-------------\")\n",
    "    print(i)\n",
    "    print('\\n')\n",
    "    print(find_word(s_result, i))\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for target in target_word:\n",
    "    target_index = []\n",
    "    for index, review in enumerate(ms_lst):\n",
    "        if target in review:\n",
    "            target_index.append(index)\n",
    "    ms_df.loc[target_index].to_csv(interprete_path + 'ms_' + target + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ap_df, ap_lst, ap_txt = brands_text(documents, data, 'Apple')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "window = 3\n",
    "min_count = 10\n",
    "\n",
    "bigram_measures = nltk.collocations.BigramAssocMeasures()\n",
    "s_finder = BigramCollocationFinder.from_words(ms_txt, window_size = window)\n",
    "\n",
    "s_finder.apply_freq_filter(min_count) #13번 미만으로 나온 것들 무시\n",
    "#finder.nbest(bigram_measures.pmi, 20)\n",
    "s_result = s_finder.score_ngrams(bigram_measures.pmi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------\n",
      "her\n",
      "\n",
      "\n",
      "[(('her', 'laptop'), 4.561330754502553), (('for', 'her'), 2.0297882191671235), (('on', 'her'), 1.8035128078929787), (('with', 'her'), 1.7630697977596306), (('her', 'and'), 0.9964473801758444), (('to', 'her'), 0.9059325517441152), (('her', 'to'), 0.58400445685675)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "loved\n",
      "\n",
      "\n",
      "[(('i', 'loved'), 3.043955855858883), (('loved', 'it'), 2.6805223138840084), (('loved', 'this'), 2.2880353768242436), (('and', 'loved'), 2.044850844516443), (('loved', 'the'), 1.55474342545617)]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-------------\n",
      "ever\n",
      "\n",
      "\n",
      "[(('ever', 'used'), 5.481768259682067), (('ever', 'since'), 5.074487096004162), (('best', 'ever'), 4.703689590231281), (('ever', 'made'), 4.661552957705688), (('have', 'ever'), 3.529506156312241), (('ever', 'had'), 3.40712252760396), (('than', 'ever'), 3.239271786100222), (('ever', 'need'), 3.210537353749981), (('what', 'ever'), 3.2094752903616204), (('i', 'ever'), 2.575680335683046), (('ever', 'get'), 2.479130829132348)]\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#pmi\n",
    "target_word = ['her', 'loved','ever']\n",
    "for i in target_word:\n",
    "    print( \"-------------\")\n",
    "    print(i)\n",
    "    print('\\n')\n",
    "    print(find_word(s_result, i))\n",
    "    print('\\n')\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for target in target_word:\n",
    "    target_index = []\n",
    "    for index, review in enumerate(ap_lst):\n",
    "        if target in review:\n",
    "            target_index.append(index)\n",
    "    ap_df.loc[target_index].to_csv(interprete_path + 'apple_' + target + '.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
